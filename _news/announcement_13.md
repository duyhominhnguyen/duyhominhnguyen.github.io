---
layout: post
date: 2025-09-26 00:00:00-0000
inline: true
related_posts: false
---

ðŸ”” **Excited to share that our following works have been accepted to [NeurIPS 2025](https://neurips.cc/)!** ðŸŽ‰  

(i) **[ExGra-Med](https://exgra-med.github.io/)** â€” a *data-efficient multimodal large language model (LLM) for healthcare*, designed to militage data-hungry of auto-regressive scheme on domain shifts.

(ii) **[Token Redundancy in 3D Point Cloud Transformers](https://openreview.net/pdf?id=uGO1tgU3Mc)** â€” uncovering how existing 3D transformers (e.g., Ptv-3, Sonata) are **over-tokenized**, and proposing an efficient *token merging* strategy that reduces computation by up to **95%** while preserving accuracy.  

(iii) **[Over-Optimization in RLHF for LLM Post-Training](https://arxiv.org/pdf/2506.08681)** â€” exploring how **reinforcement learning from human feedback (RLHF)** can lead to alignment instability and proposing new insights into optimization robustness for LLM fine-tuning.  

Huge thanks to all collaborators and mentors who made these projects possible. Excited to present and discuss them at San Diego ðŸš€

