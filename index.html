<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Duy H. M. Nguyen </title> <meta name="author" content="Duy H. M. Nguyen"> <meta name="description" content="brief information about my research interests and publications. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://duyhominhnguyen.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">curriculum vitae </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Duy</span> H. M. Nguyen </h1> <p class="desc">Nguyen Ho Minh Duy</p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/prof_pic.jpg?3fed7e056aa08374cfb1329238bddd01" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p>UniversitÃ¤tsstraÃŸe 32</p> <p>70569 Stuttgart, Germany</p> <p>Room: 2.321</p> </div> </div> <div class="clearfix"> <p>I am currently a final-year Ph.D. Candidate under the supervision of <a href="https://www.matlog.net/" rel="external nofollow noopener" target="_blank">Prof. Mathias Niepert</a> at Max Planck Research School for Intelligent Systems (<a href="https://imprs.is.mpg.de/" rel="external nofollow noopener" target="_blank">IMPRS-IS</a>) and <a href="https://www.simtech.uni-stuttgart.de/" rel="external nofollow noopener" target="_blank">University of Stuttgart</a>. I have also been a Researcher at the German Research Center for Artificial Intelligence (<a href="https://www.dfki.de/en/web" rel="external nofollow noopener" target="_blank">DFKI</a>) since 2021.</p> <p>My topics of interest are</p> <ul> <li>Hybrid Discrete-Continuous Learning (differentiable relaxations for discrete intermediate representations)</li> <li>Scalable Algorithms for Multi-modal Learning with applications for Healthcare, Simulation Science</li> <li>Efficient Deep Learning (model compression, accelerated training/inference, etc.)</li> </ul> <p>Please visit my <a href="https://scholar.google.com/citations?user=_NIyeykAAAAJ" rel="external nofollow noopener" target="_blank">Google Scholar</a> for a full list of publications and <a href="https://github.com/duyhominhnguyen" rel="external nofollow noopener" target="_blank">GitHub</a> for source codes.</p> </div> <h2> news </h2> <div class="news"> <div class="table-responsive" style="max-height: 23vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Feb 01, 2026</th> <td> ğŸ”” Happy to share our latest work <strong><a href="https://arxiv.org/pdf/2511.06754" rel="external nofollow noopener" target="_blank">Slot-VLA</a></strong>, accepted at <strong><a href="https://2026.ieee-icra.org/" rel="external nofollow noopener" target="_blank">ICRA 2026</a></strong> in Vienna, Austria ğŸ‡¦ğŸ‡¹ ğŸ‰. We show that <strong>objectâ€“relationâ€“centric slot representations</strong> enable <em>compact, interpretable, and efficient multi-task robotic manipulation</em>, drastically reducing token complexity while maintaining strong performance and generalization. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 26, 2026</th> <td> ğŸ”” Our work, namely <strong><a href="https://openreview.net/pdf?id=cpwbXHvd2h" rel="external nofollow noopener" target="_blank">FACET</a></strong>, which introduces scalable structure-aware and fragment-level modeling via Graph Transformers for molecular learning, has been accepted to <strong><a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR 2026</a></strong> ğŸ‡§ğŸ‡·! </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 06, 2026</th> <td> ğŸ† The <strong><a href="https://openreview.net/pdf?id=2wAZjAtK16" rel="external nofollow noopener" target="_blank">DuFal</a></strong> paper has been accepted at <strong>Transactions on Machine Learning Research (<a href="https://jmlr.org/tmlr/" rel="external nofollow noopener" target="_blank">TMLR</a>)</strong> 2026 and <strong>be awarded with a</strong> <a href="https://jmlr.org/tmlr/editorial-policies.html" rel="external nofollow noopener" target="_blank"><strong>J2C Certification</strong></a>. We will present the paper at the International Conference on Machine Learning <strong>(<a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a>)</strong> in July 2026, South Korea ğŸ‡°ğŸ‡·. </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 04, 2025</th> <td> ğŸ”” Our new work, <em>Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-View CBCT Reconstruction</em>, has been accepted (with minor revision) to <strong>Transactions on Machine Learning Research (<a href="https://jmlr.org/tmlr/" rel="external nofollow noopener" target="_blank">TMLR</a>)</strong> 2025. Check it out (<a href="https://openreview.net/forum?id=2wAZjAtK16&amp;referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DTMLR%2FAuthors%23your-submissions)" rel="external nofollow noopener" target="_blank">here</a>)! </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 08, 2025</th> <td> ğŸ”” Exciting News! Weâ€™re thrilled to share that our two recent works have been accepted to <strong><a href="https://aaai.org/conference/aaai/aaai-26/" rel="external nofollow noopener" target="_blank">AAAI 2026</a></strong> in Singapore ğŸ‡¸ğŸ‡¬ â€” one as an <strong>oral</strong> and the other as a <strong>poster</strong> presentation! ğŸ‰ i. <strong>Multi-Mood</strong> â€” a multi-modal large language model that integrates <strong>video, audio, and text</strong> with <strong>psychological criteria</strong> through <strong>reinforcement learning</strong> to enable <em>trustworthy and emotionally aligned responses</em>. ii. <strong>LIBERO-Mem</strong> â€” a non-Markovian task suite for <strong>short- and long-horizon object tracking and manipulation</strong>, featuring <strong>temporally sequenced subgoals</strong> that challenge models to reason <em>beyond the current observation</em>. ğŸ“„ <strong>Codes</strong> will be released soon ğŸ‰ â€” stay tuned! </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 26, 2025</th> <td> ğŸ”” Excited to share that our works on (i) <strong><a href="https://exgra-med.github.io/" rel="external nofollow noopener" target="_blank">ExGra-Med</a></strong> â€” a <em>data-efficient multimodal large language model (LLM) for healthcare</em>; (ii) <strong><a href="https://openreview.net/pdf?id=uGO1tgU3Mc" rel="external nofollow noopener" target="_blank">Token Redundancy in 3D Point Cloud Transformers</a></strong> â€” uncovering how existing 3D transformers (e.g., Ptv-3, Sonata) are <strong>over-tokenized</strong>, and proposing an efficient <em>token merging</em> strategy that reduces computation by up to <strong>90-95%</strong> while preserving accuracy; and (iii) <strong><a href="https://arxiv.org/pdf/2506.08681" rel="external nofollow noopener" target="_blank">Over-Optimization in RLHF for LLM Post-Training</a></strong> â€” exploring how <strong>reinforcement learning from human feedback</strong> can lead to alignment instability and proposing new insights into optimization LLM post-training have been accepted to <strong><a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS 2025</a></strong> ğŸ‰. Excited to present and discuss them at San Diego ğŸ‡ºğŸ‡¸ ğŸš€ </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 09, 2025</th> <td> ğŸŒŸ Excited to give a talk about my current research on <strong>Scaling Multi-Modal Learning: Hybrid Representations and Efficient Adaptation</strong> at Machine Learning Lab, School of Information and Communications Technology (<a href="https://soict.hust.edu.vn/soict-seminar-scaling-multi-modal-learning-hybrid-representations-and-efficient-adaptation.html" rel="external nofollow noopener" target="_blank">SOICT</a>), Hanoi University of Science and Technology, Vietnam and (ii) School of Computing, National University of Singapore (<a href="https://www.comp.nus.edu.sg/" rel="external nofollow noopener" target="_blank">NUS</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 02, 2025</th> <td> <img class="emoji" title=":bell:" alt=":bell:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f514.png" height="20" width="20"> The <a href="https://openreview.net/forum?id=u7U81JLGjH" rel="external nofollow noopener" target="_blank">MGPath</a> has been accepted to the <strong>Transactions on Machine Learning Research</strong>. Congratulations to all co-authors on this milestone! </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2025</th> <td> ğŸ‰ Our first (i) preliminary version, <a href="https://openreview.net/pdf?id=nJZtYrOeoV" rel="external nofollow noopener" target="_blank">MGPath</a> has been accepted to the <strong>Workshop on Foundation Models in the Wild, ICLR 2025</strong> and (ii) another one about <a href="https://arxiv.org/pdf/2502.03029" rel="external nofollow noopener" target="_blank">LLaMA-Adapterâ€™s prompt learning</a> is accepted at <strong>ICML 2025</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 20, 2025</th> <td> ğŸ‰ Our work in building a new <a href="https://www.nature.com/articles/s41598-025-94593-y" rel="external nofollow noopener" target="_blank">Inductive Message Passing Network for Efficient Human-in-the-Loop Annotation of Mobile Eye Tracking Data</a> has been accepted at <strong>Scientific Report, Nature Portfolio</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 20, 2025</th> <td> <img class="emoji" title=":bell:" alt=":bell:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f514.png" height="20" width="20"> Excited to share our latest work! ğŸ‰: (i) <a href="https://arxiv.org/pdf/2502.03029" rel="external nofollow noopener" target="_blank">On Zero-Initialized Attention: Optimal Prompt and Gating Factor Estimation</a> â€“ We introduce a Mixture of Experts (MoE) perspective to explain the mechanism behind LLaMA-Adapterâ€™s prompt learning. (ii) <a href="https://arxiv.org/pdf/2502.07409" rel="external nofollow noopener" target="_blank">MGPath</a> â€“ A novel multi-granular prompt learning method for few-shot WSI pathology prediction, leveraging the power of foundation vision-language models. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 08, 2024</th> <td> ğŸ‡¨ğŸ‡­ Start my visiting research at <a href="https://ai.ethz.ch/" rel="external nofollow noopener" target="_blank">ETH AI Center</a>, <a href="https://ethz.ch/en.html" rel="external nofollow noopener" target="_blank">ETH Zurich</a>. The topics are about Multi-Modal LLMs for Healthcare empowered by Retrieval-Augmented Generation. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 07, 2024</th> <td> <img class="emoji" title=":bell:" alt=":bell:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f514.png" height="20" width="20"> Excited to introduce our latest work on medical multi-modal LLMs: <a href="https://arxiv.org/abs/2410.02615" rel="external nofollow noopener" target="_blank">LoGra-Med</a>, a novel pre-training algorithm that incorporates multi-graph alignment to effectively address the data-hungry nature of autoregressive learning. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 06, 2024</th> <td> <img class="emoji" title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"> The paper <a href="https://arxiv.org/abs/2405.16148" rel="external nofollow noopener" target="_blank">PiToMe</a> has been accepted at <strong>NeurIPS 2024</strong>. Our code will be available soon! </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 10, 2024</th> <td> <img class="emoji" title=":bell:" alt=":bell:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f514.png" height="20" width="20"> Our new preprint <a href="https://arxiv.org/abs/2405.16148" rel="external nofollow noopener" target="_blank">PiToMe</a> is online. We propose a new method to do token merging in the Transformer with spectrum-preserving. </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2024</th> <td> <img class="emoji" title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"> A paper submitted to <strong>ICML 2024</strong> on the <a href="https://arxiv.org/abs/2402.01975" rel="external nofollow noopener" target="_blank">molecular conformer aggregation network</a> topic is accepted. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 15, 2024</th> <td> <img class="emoji" title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"> A paper submitted to <strong>ICLR 2024</strong> on the topic of <a href="https://openreview.net/forum?id=R7dCHc2Rp0" rel="external nofollow noopener" target="_blank">accelerating transformers</a> is accepted as an oral talk. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 22, 2023</th> <td> <img class="emoji" title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"> A paper submitted to <strong>NeurIPS 2023</strong> on a <a href="https://arxiv.org/abs/2306.11925" rel="external nofollow noopener" target="_blank">large-scale medical image pre-trained models using second-order graph matching</a> is accepted. </td> </tr> </table> </div> </div> <p style="margin-bottom:1cm;"> </p> <h2> preprints </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Under Review</abbr> <figure> <picture> <img src="/assets/img/publication_preview/svcot.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="svcot.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="khainguyen2025svcot" class="col-sm-8"> <div class="title">S-Chain: Structured Visual Chain-of-Thought for Medicine</div> <div class="author"> Khai Le-Duc*,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen*</a>,Â  Phuong T.H. Trinh* ,Â  Tien-Phat Nguyen*,Â  et al. </div> <div class="periodical"> <em></em> 2025 </div> <div class="periodical"> <em>*Co-first contributions</em> </div> <div class="links"> <a href="https://arxiv.org/pdf/2510.22728" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://s-chain.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Under Review</abbr> <figure> <picture> <img src="/assets/img/publication_preview/SELF.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="SELF.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="phucnguyen2025reasoning" class="col-sm-8"> <div class="title">The Reasoning Boundary Paradox: How Reinforcement Learning Constrains Language Models</div> <div class="author"> Phuc Minh Nguyen,Â  Chinh D La,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Nitesh V Chawla ,Â  Binh T Nguyen,Â  Khoa D Doan </div> <div class="periodical"> <em></em> 2025 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://arxiv.org/pdf/2510.02230" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/mail-research/SELF-llm-interference" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> </ol> </div> <h2> selected publications </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> <figure> <picture> <img src="/assets/img/publication_preview/facet.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="facet.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="duynguyen2026from" class="col-sm-8"> <div class="title">FACET: A Fragment-Aware Conformer Ensemble Transformer</div> <div class="author"> <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a> ,Â  Trung Quoc Nguyen,Â  Ha Thi Hong Le,Â  Mai TN Truong ,Â  TrungTin Nguyen,Â  Nhat Ho,Â  Khoa D Doan,Â  Duy Duong-Tran,Â  Li Shen,Â  Daniel Sonntag, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'James Zou, Mathias Niepert, Hyojin Kim, Jonathan E Allen' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>International Conference on Learning Representations (ICLR)</em>, 2026 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://openreview.net/pdf?id=cpwbXHvd2h" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICRA</abbr> <figure> <picture> <img src="/assets/img/publication_preview/slot_vla.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="slot_vla.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Taisei2026slotvla" class="col-sm-8"> <div class="title">SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation</div> <div class="author"> Taisei Hanyu,Â  Nhat Chung,Â  Huy Le ,Â  Toan Nguyen,Â  Yuki Ikebe,Â  Anthony Gunderman,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Khoa Vo,Â  Tung Kieu,Â  Kashu Yamazaki, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Chase Rainwater, Anh Nguyen, Ngan Le' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2026 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://arxiv.org/pdf/2511.06754" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TMLR</abbr> <figure> <picture> <img src="/assets/img/publication_preview/TMLR_2025_DuFal.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="TMLR_2025_DuFal.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="cuong2026dual" class="col-sm-8"> <div class="title">DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction</div> <div class="author"> Cuong Tran Van,Â  Thang-Trong Pham ,Â  Ngoc-Son Nguyen,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Ngan Le </div> <div class="periodical"> <em>Transactions on Machine Learning Research (TMLR)</em>, 2026 </div> <div class="periodical"> <em>J2C Certification Award, to be presented at the International Conference on Machine Learning (ICML) 2026, South Korea.</em> </div> <div class="links"> <a href="https://openreview.net/pdf?id=2wAZjAtK16" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/UARK-AICV/DuFal" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI (Oral)</abbr> <figure> <picture> <img src="/assets/img/publication_preview/AAAI_2025_Multimood.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="AAAI_2025_Multimood.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="huyle2026retrust" class="col-sm-8"> <div class="title">Reinforce Trustworthiness in Multimodal Emotional Support System</div> <div class="author"> Huy M. Le ,Â  Dat Tien Nguyen,Â  Ngan T. T. Vo ,Â  Tuan D. Q. Nguyen,Â  Nguyen Le Binh,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Daniel Sonntag,Â  Lizi Liao ,Â  Binh T. Nguyen </div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 2026 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://arxiv.org/pdf/2511.10011" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <img src="/assets/img/publication_preview/AAAI_2026_Libero_Non_Markov.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="AAAI_2026_Libero_Non_Markov.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nhatchung2026repro" class="col-sm-8"> <div class="title">Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective</div> <div class="author"> Nhat Chung,Â  Taisei Hanyu ,Â  Toan Nguyen,Â  Huy Le,Â  Frederick Bumgarner,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Khoa Vo,Â  Kashu Yamazaki,Â  Chase Rainwater,Â  Tung Kieu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Anh Nguyen, Ngan Le' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 2026 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://arxiv.org/pdf/2511.11478" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://libero-mem.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <img src="/assets/img/publication_preview/exgramed.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="exgramed.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="duynguyen2025exgra" class="col-sm-8"> <div class="title">ExGra-Med: Extended Context Graph Alignment for Medical Vision-Language Models</div> <div class="author"> <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Nghiem T. Diep ,Â  Trung Q. Nguyen,Â  Hoang-Bao Le ,Â  Tai Nguyen ,Â  Tien Nguyen ,Â  TrungTin Nguyen,Â  Nhat Ho,Â  Pengtao Xie,Â  Roger Wattenhofer, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'James Zou, Daniel Sonntag, Mathias Niepert' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2025 </div> <div class="periodical"> <em>Short version was accepted at Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences, ICML 2025</em> </div> <div class="links"> <a href="https://openreview.net/pdf?id=TjWdyVWBAG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://exgra-med.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <img src="/assets/img/publication_preview/3d_point.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="3d_point.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tuananh2025how" class="col-sm-8"> <div class="title">How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?</div> <div class="author"> Tuan Anh Tran,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Hoai-Chau Tran,Â  Michael Barz,Â  Khoa D Doan,Â  Roger Wattenhofer,Â  Vien Anh Ngo,Â  Mathias Niepert,Â  Daniel Sonntag,Â  Paul Swoboda </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2025 </div> <div class="periodical"> <em>Short version was accepted at 3rd Workshop on Efficient Systems for Foundation Models, ICML 2025</em> </div> <div class="links"> <a href="https://openreview.net/pdf?id=cFVQJepi4e" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitmerge3d.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <img src="/assets/img/publication_preview/sampling.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sampling.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="phuc2025mitigating" class="col-sm-8"> <div class="title">Mitigating Reward Over-optimization in Direct Alignment Algorithms with Importance Sampling</div> <div class="author"> Phuc Minh Nguyen ,Â  Ngoc-Hieu Nguyen,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Anji Liu,Â  An Mai ,Â  Binh T. Nguyen,Â  Daniel Sonntag,Â  Khoa D. Doan </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2025 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://openreview.net/pdf?id=ltPRj2nthL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/duyhominhnguyen/IS-DAAs/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TMLR</abbr> <figure> <picture> <img src="/assets/img/publication_preview/TMLR_2025.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="TMLR_2025.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="anhtien2025mgpath" class="col-sm-8"> <div class="title">MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification</div> <div class="author"> Anh-Tien Nguyen,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Nghiem Tuong Diep ,Â  Trung Quoc Nguyen,Â  Nhat Ho,Â  Jacqueline Michelle Metsch,Â  Miriam Cindy Maurer,Â  Daniel Sonntag,Â  Hanibal Bohnenberger,Â  Anne-Christin Hauschild </div> <div class="periodical"> <em>Transactions on Machine Learning Research (TMLR)</em>, 2025 </div> <div class="periodical"> <em>Short version was accepted at Workshop on Foundation Models in the Wild, ICLR 2025</em> </div> <div class="links"> <a href="https://openreview.net/pdf?id=u7U81JLGjH" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/HauschildLab/MGPATH" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> <figure> <picture> <img src="/assets/img/publication_preview/ICML_2025.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ICML_2025.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="diep2025zero" class="col-sm-8"> <div class="title">On Zero-Initialized Attention: Optimal Prompt and Gating Factor Estimation</div> <div class="author"> Nghiem T. Diep* ,Â  Huy Nguyen* ,Â  Chau Nguyen*,Â  Minh Le,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Daniel Sonntag,Â  Mathias Niepert,Â  Nhat Ho </div> <div class="periodical"> <em>International Conference on Machine Learning (ICML)</em>, 2025 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://arxiv.org/pdf/2502.03029" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/duyhominhnguyen/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <img src="/assets/img/publication_preview/NeurIPS_2024.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="NeurIPS_2024.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tran2024accelerating" class="col-sm-8"> <div class="title">Accelerating Transformers with Spectrum-Preserving Token Merging</div> <div class="author"> Hoai-Chau Tran*,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen*</a> ,Â  Duy M Nguyen ,Â  Trung-Tin Nguyen,Â  Ngan Le,Â  Pengtao Xie,Â  Daniel Sonntag,Â  James Y Zou ,Â  Binh T Nguyen,Â  Mathias Niepert </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2024 </div> <div class="periodical"> <em>*Co-first contributions</em> </div> <div class="links"> <a href="https://arxiv.org/abs/2405.16148" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/hchautran/PiToMe" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> <figure> <picture> <img src="/assets/img/publication_preview/ICML_2024.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ICML_2024.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nguyen2024structure" class="col-sm-8"> <div class="title">Structure-aware E(3)-invariant molecular conformer aggregation networks</div> <div class="author"> <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Nina Lukashina ,Â  Tai Nguyen,Â  An T Le ,Â  TrungTin Nguyen,Â  Nhat Ho,Â  Jan Peters,Â  Daniel Sonntag,Â  Viktor Zaverkin,Â  Mathias Niepert </div> <div class="periodical"> <em>International Conference on Machine Learning (ICML)</em>, 2024 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://arxiv.org/abs/2402.01975" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/duyhominhnguyen/conan-fgw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR (Oral)</abbr> <figure> <picture> <img src="/assets/img/publication_preview/ICLR_2024.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ICLR_2024.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tranenergy" class="col-sm-8"> <div class="title">Energy minimizing-based token merging for accelerating Transformers</div> <div class="author"> Hoai-Chau Tran*,Â  <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen*</a> ,Â  Manh-Duy Nguyen,Â  Ngan Hoang Le ,Â  Binh T Nguyen </div> <div class="periodical"> <em>5th Workshop on practical ML for limited/low resource settings, International Conference on Learning Representations (ICLR)</em>, 2024 </div> <div class="periodical"> <em>*Co-first contributions</em> </div> <div class="links"> <a href="https://openreview.net/forum?id=R7dCHc2Rp0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <img src="/assets/img/publication_preview/NeurIPS_2023.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="NeurIPS_2023.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mh2024lvm" class="col-sm-8"> <div class="title">LVM-Med: Learning large-scale self-supervised vision models for medical imaging via second-order graph matching</div> <div class="author"> <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a> ,Â  Hoang Nguyen,Â  Nghiem Diep,Â  Tan Ngoc Pham,Â  Tri Cao ,Â  Binh Nguyen,Â  Paul Swoboda,Â  Nhat Ho,Â  Shadi Albarqouni,Â  Pengtao Xie, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' others' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2023 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://arxiv.org/abs/2306.11925" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/duyhominhnguyen/LVM-Med" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <img src="/assets/img/publication_preview/AAAI_2023.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="AAAI_2023.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nguyen2023joint" class="col-sm-8"> <div class="title">Joint self-supervised image-volume representation learning with intra-inter contrastive clustering</div> <div class="author"> <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a> ,Â  Hoang Nguyen,Â  Truong TN Mai,Â  Tri Cao ,Â  Binh T Nguyen,Â  Nhat Ho,Â  Paul Swoboda,Â  Shadi Albarqouni,Â  Pengtao Xie,Â  Daniel Sonntag </div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 2023 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26687" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/duyhominhnguyen/Self-supervised-Image-Volume-Intra-Inter-Contrastive" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <img src="/assets/img/publication_preview/CVPR_2022.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CVPR_2022.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nguyen2022lmgp" class="col-sm-8"> <div class="title">LMGP: Lifted multicut meets geometry projections for multi-camera multi-object tracking</div> <div class="author"> <a href="https://duyhominhnguyen.github.io/">Duy MH Nguyen</a>,Â  Roberto Henschel,Â  Bodo Rosenhahn,Â  Daniel Sonntag,Â  Paul Swoboda </div> <div class="periodical"> <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022 </div> <div class="periodical"> <em></em> </div> <div class="links"> <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_LMGP_Lifted_Multicut_Meets_Geometry_Projections_for_Multi-Camera_Multi-Object_Tracking_CVPR_2022_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6E%68%6D%64%75%79.%68%63%6D%75%73@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=_NIyeykAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Duy-Nguyen-34/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://github.com/duyhominhnguyen" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2026 Duy H. M. Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>